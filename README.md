# Sistema de IA Generativa Multi-Funcional

## Funcionalidades Principais

### Sistema de Provedores Extens√≠vel

- **Plugin System** - Adicione novos provedores de LLM sem modificar c√≥digo existente
- **Auto-Discovery** - Novos provedores s√£o detectados e registrados automaticamente  
- **Fallback Inteligente** - Sistema escolhe o melhor provedor dispon√≠vel
- **Zero Regress√£o** - C√≥digo existente permanece intocado ao adicionar funcionalidades
- **Configura√ß√µes Globais Centralizadas** - Par√¢metros unificados para todos os providers

### Chatbot Inteligente
- **Conversa natural** com mem√≥ria de contexto
- **Diferentes personalidades** configur√°veis (helpful, creative, technical)
- **Switching din√¢mico** entre provedores LLM
- **Interface moderna** com componentes UI especializados

### An√°lise de Sentimentos
- **An√°lise contextual** usando LLM
- **Precis√£o alta** em diferentes linguages
- **Explica√ß√µes detalhadas** dos resultados
- **M√©tricas de confian√ßa** precisas

### Gera√ß√£o de Resumos
- **Diferentes estrat√©gias**: Extrativa (NLTK) + Generativa (LangChain)
- **Tipos de resumo**: Informativo, Executivo, Criativo, T√©cnico
- **Compara√ß√£o autom√°tica** de m√©todos
- **M√©tricas de compress√£o** detalhadas

### Analytics & Monitoramento
- **Status em tempo real** dos provedores
- **M√©tricas de performance** e uso
- **Estat√≠sticas da sess√£o** detalhadas
- **Dashboard de configura√ß√µes globais**

## Tecnologias Utilizadas

- **üêç Python 3.8+** - Linguagem principal
- **üîó LangChain** - Framework para aplica√ß√µes LLM
- **üöÄ Groq API** - LLM r√°pido e gratuito (Llama 3, Mixtral)
- **ü§ó Hugging Face** - 91+ modelos open-source via API unificada
- **üì± Streamlit** - Interface web interativa
- **üìä NLTK** - Processamento de linguagem natural
- **üîß Pydantic** - Valida√ß√£o de dados
- **üì¶ Pandas/NumPy** - Manipula√ß√£o de dados
- **üèóÔ∏è ABC (Abstract Base Classes)** - Interfaces e contratos

## Configura√ß√£o e Execu√ß√£o

### 1. **Clonar o Reposit√≥rio**
```bash
git clone <ChatBot-Simples>
cd ChatBot
```

### 2. **Instalar as Depend√™ncias**
```bash
pip install -r requirements.txt
```

### 3. **Configura√ß√£o Multi-Provider Automatizada**

O sistema inclui um setup inteligente que configura automaticamente **Groq** e **Hugging Face**, al√©m de gerar templates para outros providers:

```bash
python setup_env.py
```

**O que o setup faz:**
- **Configura Groq** (gratuito) - provider principal ultra-r√°pido
- **Configura Hugging Face** (gratuito) - 91+ modelos open-source dispon√≠veis
- **Gera templates prontos** para OpenAI, Claude, Gemini, etc.
- **Configura√ß√µes globais centralizadas** (timeout, retry, debug)
- **Documenta√ß√£o inline** com links e instru√ß√µes
- **Valida√ß√£o autom√°tica** de chaves API
- **Teste de configura√ß√£o** p√≥s-setup

#### **Configura√ß√£o Manual Alternativa**
Ou tamb√©m, para configura√ß√£o manual, crie o arquivo `.env`:
```env
# Provider principal (ultra-r√°pido)
GROQ_API_KEY=sua_chave_groq_aqui

# Provider com m√∫ltiplos modelos open-source  
HUGGINGFACE_API_KEY=sua_chave_hf_aqui

# Configura√ß√µes globais (aplicadas a todos os providers)
GLOBAL_TEMPERATURE=0.7
GLOBAL_MAX_TOKENS=1000
API_TIMEOUT=30
```

**Para obter chaves gratuitas:**
- **Groq**: [console.groq.com](https://console.groq.com/)
- **Hugging Face**: [huggingface.co/settings/tokens](https://huggingface.co/settings/tokens)

### 4. **Executar a Aplica√ß√£o**
```bash
streamlit run app.py
```

### 5. **Ativa√ß√£o R√°pida de Outros Providers**

O arquivo `.env` gerado j√° inclui **templates comentados** para ativa√ß√£o r√°pida:

```env
# Para ativar OpenAI: descomente e configure
# OPENAI_API_KEY=sk-proj-sua_chave_openai_aqui
# OPENAI_DEFAULT_MODEL=gpt-3.5-turbo

# Para ativar Claude: descomente e configure  
# ANTHROPIC_API_KEY=sk-ant-sua_chave_claude_aqui
# CLAUDE_DEFAULT_MODEL=claude-3-haiku-20240307

# Para ativar Gemini: descomente e configure
# GOOGLE_API_KEY=sua_chave_google_aqui
# GEMINI_DEFAULT_MODEL=gemini-pro
```

**Providers com templates prontos:**
- **OpenAI** (GPT-3.5, GPT-4, GPT-4o)
- **Anthropic Claude** (Haiku, Sonnet, Opus)  
- **Google Gemini** (Gemini Pro, Vision)
- **Cohere** (Command, Command-Light)
- **Azure OpenAI** (configura√ß√£o completa)

## Arquitetura do Sistema

### **Componentes Principais**

#### **1. Provider Registry (`src/provider_registry.py`)**
- **Registro autom√°tico** de novos provedores
- **Sele√ß√£o inteligente** do melhor provider dispon√≠vel  
- **Switching din√¢mico** entre providers
- **Fallback** em caso de indisponibilidade

#### **2. Configura√ß√µes Globais (`src/config.py`)**
- **Centralizadas** - par√¢metros aplicados a todos os providers
- **Environment-based** - configura√ß√£o via `.env`
- **Override support** - permite customiza√ß√£o por provider
- **Debug mode** e logging configur√°vel

#### **3. Componentes UI (`src/ui/components.py`)**
- **Single Responsibility** - cada componente tem uma fun√ß√£o espec√≠fica
- **Reutiliz√°veis** - componentes modulares e focados
- **Factory Pattern** - cria√ß√£o especializada de conjuntos de componentes
- **Separa√ß√£o clara** entre input, display, validation e settings

#### **4. Interfaces Abstratas (`src/interfaces.py`)**
- **Contratos claros** entre componentes
- **Implementa√ß√£o obrigat√≥ria** de m√©todos essenciais
- **Type safety** com typing hints
- **Documenta√ß√£o integrada**

### **Providers Implementados**

#### **Groq Provider (`src/providers/groq_provider.py`)**
- **Ultra-r√°pido** - API otimizada para velocidade
- **Gratuito** - 30 requests/minuto sem custo
- **Modelos**: Llama 3 70B, Llama 3 8B
- **Configura√ß√µes globais** aplicadas automaticamente

#### **Hugging Face Provider (`src/providers/huggingface_provider.py`)**
- **91+ modelos** dispon√≠veis via API unificada
- **OpenAI-compatible** - formato de requisi√ß√£o padronizado
- **Modelos testados**: Gemma 2, DeepSeek R1, Phi-4, Qwen2.5-Coder
- **Rate limits generosos** - 1,000+ requests/dia gratuito

## Como Adicionar um Novo Provedor

### **M√©todo R√°pido: Usar Templates**

1. **Configure o ambiente:**
   ```bash
   python setup_env.py  # Gera templates prontos
   ```

2. **Ative um provider:**
   - Abra o arquivo `.env` gerado
   - Descomente a se√ß√£o do provider desejado
   - Configure sua API key
   - Salve o arquivo

3. **Implemente o provider (se n√£o existir):**
   - Copie um template de `src/providers/` 
   - Customize para sua API
   - Adicione ao `__init__.py`

### **M√©todo Detalhado: Implementa√ß√£o Customizada**

### 1. **Criar o Arquivo do Provedor**

Use os providers existentes como base:
- `groq_provider.py` - Implementa√ß√£o com LangChain
- `huggingface_provider.py` - Implementa√ß√£o com requests

Ou use os templates como base:
- `openai_provider_example.py` - Template OpenAI
- `claude_provider_example.py` - Template Claude

```python
from src.interfaces import ILLMProvider
from src.config import GlobalConfig

class MeuProvedor(ILLMProvider):
    def __init__(self):
        self.name = "meu_provider"
        # Usa configura√ß√µes globais centralizadas
        self.params = GlobalConfig.get_generation_params()
        self._setup()
    
    # Implementar todos os m√©todos abstratos da interface
```

### 2. **Implementar M√©todos Obrigat√≥rios**

Todos os provedores devem implementar a interface `ILLMProvider`:

```python
def get_name(self) -> str:
    """Nome √∫nico do provedor"""
    
def is_available(self) -> bool:
    """Verifica se est√° configurado e dispon√≠vel"""
    
def generate_response(self, message: str, **kwargs) -> str:
    """Gera resposta usando a API"""
    
def get_info(self) -> Dict[str, Any]:
    """Informa√ß√µes sobre o provedor"""
    
def get_available_models(self) -> List[str]:
    """Lista modelos dispon√≠veis"""
    
def switch_model(self, model: str) -> bool:
    """Troca modelo ativo"""
    
def get_current_model(self) -> str:
    """Modelo atual"""
    
def get_performance_stats(self) -> Dict[str, Any]:
    """Estat√≠sticas de performance"""
```

### 3. **Atualizar Exporta√ß√µes**

Edite `src/providers/__init__.py` para exportar o novo provedor:

```python
from .groq_provider import GroqProvider
from .huggingface_provider import HuggingFaceProvider
from .meu_provider import MeuProvedor  # Adicione esta linha

__all__ = ['GroqProvider', 'HuggingFaceProvider', 'MeuProvedor']  # Adicione ao __all__
```

### 4. **Registro Autom√°tico**

O sistema registra automaticamente novos provedores atrav√©s do `ProviderRegistry`. O registro acontece automaticamente no `__init__()` do registry.

### 5. **Configura√ß√£o de Environment**

Adicione vari√°veis necess√°rias no `.env`:

```env
MEU_PROVIDER_API_KEY=sua_chave_aqui
MEU_PROVIDER_DEFAULT_MODEL=modelo_padrao
```

### 6. **Usar Configura√ß√µes Globais**

Aproveite as configura√ß√µes centralizadas:

```python
from src.config import GlobalConfig

# Em __init__ ou _setup
params = GlobalConfig.get_generation_params()
self.temperature = params["temperature"]
self.max_tokens = params["max_tokens"]

# Com overrides espec√≠ficos se necess√°rio
params = GlobalConfig.get_generation_params(temperature=0.9)
```

## **Configura√ß√£o Avan√ßada**

### **Configura√ß√µes Globais Centralizadas**

O sistema usa configura√ß√µes centralizadas atrav√©s da classe `GlobalConfig`:

```env
# Par√¢metros de gera√ß√£o (aplicados a todos os providers)
GLOBAL_TEMPERATURE=0.7       # Criatividade (0.0-1.0)  
GLOBAL_MAX_TOKENS=1000       # Tamanho m√°ximo das respostas

# Configura√ß√µes de API
API_TIMEOUT=30               # Timeout para todas as APIs
AUTO_RETRY=true              # Retry autom√°tico em falhas
MAX_RETRIES=3                # M√°ximo de tentativas

# Configura√ß√µes de desenvolvimento
LOG_LEVEL=INFO               # DEBUG, INFO, WARNING, ERROR
DEBUG_MODE=false             # Modo debug para desenvolvimento
```

### **Setup Autom√°tico Inteligente**

O `setup_env.py` inclui:

#### **Funcionalidades Avan√ßadas:**
- **Valida√ß√£o autom√°tica** de chaves API (formato correto)
- **Backup autom√°tico** do `.env` existente antes de sobrescrever
- **Teste de configura√ß√£o** p√≥s-setup
- **Templates inline** com documenta√ß√£o completa
- **Pr√≥ximos passos** claros ap√≥s configura√ß√£o

#### **Modo Interativo:**
- **Configura√ß√µes avan√ßadas** opcionais (temperatura, max_tokens, modelo)
- **Instru√ß√µes contextuais** para obter cada tipo de chave
- **Valida√ß√£o em tempo real** com feedback claro

## Checklist para a Implementa√ß√£o

- [ ] Arquivo do provedor criado seguindo a interface `ILLMProvider`
- [ ] Todos os m√©todos da interface implementados
- [ ] Uso das configura√ß√µes globais via `GlobalConfig`
- [ ] Tratamento de erros robusto
- [ ] Configura√ß√£o via vari√°veis de ambiente
- [ ] Exporta√ß√£o no `src/providers/__init__.py`
- [ ] Testes b√°sicos funcionando
- [ ] Documenta√ß√£o das configura√ß√µes necess√°rias
- [ ] Performance stats implementadas
- [ ] Atualiza√ß√£o dos componentes da interface web

---

## **Recursos e Links √öteis**

### **APIs Gratuitas para Testar:**
- **Groq** (gratuito): [console.groq.com](https://console.groq.com/)
- **Hugging Face** (gratuito): [huggingface.co/settings/tokens](https://huggingface.co/settings/tokens)
- **Google AI** (trial): [ai.google.dev](https://ai.google.dev)

### **Documenta√ß√£o T√©cnica:**
- **SOLID Principles**: Projeto implementa todos os 5 princ√≠pios
- **Plugin Architecture**: Sistema extens√≠vel sem modifica√ß√µes
- **Dependency Injection**: Registry modular e test√°vel
- **Component Segregation**: UI components especializados
- **Centralized Configuration**: GlobalConfig para configura√ß√µes unificadas

### **Para Desenvolvimento:**
- **Modo Debug**: Configure `DEBUG_MODE=true` no `.env`
- **Logs Detalhados**: Configure `LOG_LEVEL=DEBUG`
- **Configura√ß√µes Customizadas**: Use overrides no `GlobalConfig`

---

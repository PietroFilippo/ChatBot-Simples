"""
Constantes centralizadas para eliminar strings hardcoded e magic numbers.
"""

from typing import Dict

# Mensagens de erro padronizadas
ERROR_MESSAGES = {
    "no_provider": "**Nenhuma API configurada**",
    "invalid_text": "Por favor, insira um texto v√°lido",
    "text_too_short": "Texto deve ter pelo menos {min_length} caracteres",
    "processing": "Processando.",
    "api_error": "Erro na API {provider}: {error}",
    "timeout": "Timeout na requisi√ß√£o. Tente novamente.",
    "model_unavailable": "Modelo '{model}' n√£o dispon√≠vel para {provider}",
    "provider_unavailable": "Provedor {provider} n√£o dispon√≠vel. Verifique a configura√ß√£o.",
    "NO_PROVIDERS": "Nenhuma API registrada",
    "SETUP_REQUIRED": "Configure uma API para usar o sistema.",
    "UNKNOWN_ERROR": "Erro desconhecido",
}

# Mensagens de sucesso
SUCCESS_MESSAGES = {
    "provider_configured": "{provider} configurado com sucesso",
    "model_switched": "Modelo alterado para: {model}",
    "analysis_complete": "An√°lise conclu√≠da",
    "history_preserved": "Hist√≥rico preservado: {count} mensagens",
    "HISTORY_CLEARED": "Hist√≥rico limpo.",
    "APIS_RELOADED": "APIs recarregadas.",
}

# Mensagens da interface do usu√°rio
UI_MESSAGES = {
    "PAGE_TITLE": "IA Generativa Multi-Funcional",
    "MAIN_HEADER": "Sistema de IA Generativa Multi-Funcional",
    "SUBTITLE": "Utiliza√ß√£o de <strong>LangChain</strong>, <strong>LLMs gratuitos</strong> e <strong>fluxos de IA</strong>",
    "PROVIDER_HELP": """Selecione o provedor de LLM.
Para configurar outras APIs de maneira local com suas chaves, baixe o reposit√≥rio do projeto e siga as instru√ß√µes.""",
    "SETUP_INSTRUCTIONS": {
        "huggingface": """
        **Para configurar Hugging Face:**
        1. Execute: `python setup_env.py`
        2. Configure sua chave quando solicitado
        3. Obtenha gr√°tis em: [huggingface.co/settings/tokens](https://huggingface.co/settings/tokens)
        """,
        "groq": """
        **Para configurar Groq:**
        1. Execute: `python setup_env.py`
        2. Configure sua chave quando solicitado
        3. Obtenha gr√°tis em: [console.groq.com](https://console.groq.com/)
        """
    },
    "SETUP_GUIDE": """
    **Configurar Groq (Gratuito):**
    ```bash
    python setup_env.py
    ```
    
    **Ou manualmente:**
    1. Acesse [console.groq.com](https://console.groq.com/)
    2. Crie uma conta gratuita
    3. Gere uma API key
    4. Crie arquivo `.env` com:
    ```
    GROQ_API_KEY=sua_chave_aqui
    ```
    """
}

# Nomes de display para providers
PROVIDER_NAMES = {
    "groq": "üöÄ Groq",
    "huggingface": "ü§ó Hugging Face",
    "openai": "ü§ñ OpenAI",
    "claude": "üß† Claude",
}

# Nomes de display para modelos
MODEL_NAMES = {
    # Groq models
    "llama3-70b-8192": "ü¶ô Llama 3 70B",
    "llama3-8b-8192": "ü¶ô Llama 3 8B",
    "gemma2-9b-it": "üî∑ Gemma 2 9B",
    
    # Hugging Face models
    "openai/gpt-oss-120b": "üíª GPT-OSS 120B",
    "google/gemma-2-2b-it": "üî∑ Gemma 2 2B Instruct",
    "deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B": "üß† DeepSeek R1 Distill 1.5B",
    "microsoft/phi-4": "üî∑ Microsoft Phi-4",
    "Qwen/Qwen2.5-Coder-32B-Instruct": "üíª Qwen 2.5 Coder 32B",
    "deepseek-ai/DeepSeek-R1": "üß† DeepSeek R1 (Reasoning)",
    "openai/gpt-oss-20b": "üíª GPT-OSS 20B",	
}

# Informa√ß√µes do sistema
SYSTEM_INFO = {
    "PROJECT_TECHNOLOGIES": """
    - LangChain
    - Groq API (gratuita)
    - Hugging Face API (gratuita)
    - An√°lise de Sentimentos (LLM)
    - Gera√ß√£o de Resumos
    - Chatbot
    """,
    "MODEL_INFO": {
        # Groq models
        "llama3-70b-8192": {"size": "70B", "speed": "R√°pido", "quality": "Excelente", "context": "8K"},
        "llama3-8b-8192": {"size": "8B", "speed": "R√°pido", "quality": "Bom", "context": "8K"},
        "gemma2-9b-it": {"size": "9B", "speed": "R√°pido", "quality": "Bom", "context": "8K"},
        
        # Hugging Face models
        "openai/gpt-oss-120b": {"size": "120B", "speed": "R√°pido", "quality": "Excelente", "context": "128K"},
        "google/gemma-2-2b-it": {"size": "2B", "speed": "R√°pido", "quality": "Bom", "context": "8K"},
        "deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B": {"size": "1.5B", "speed": "R√°pido", "quality": "Bom", "context": "32K"},
        "microsoft/phi-4": {"size": "14B", "speed": "R√°pido", "quality": "Muito Bom", "context": "16K"},
        "Qwen/Qwen2.5-Coder-32B-Instruct": {"size": "32B", "speed": "M√©dio", "quality": "Excelente", "context": "32K"},
        "deepseek-ai/DeepSeek-R1": {
            "size": "236B", 
            "speed": "Lento", 
            "quality": "Excepcional", 
            "context": "128K",
            "special": "üß† Modelo de Reasoning - Demora mais para responder pois 'pensa' antes de dar a resposta final. O output inclui o processo de racioc√≠nio completo."
        },
        "openai/gpt-oss-20b": {
            "size": "21.5B",
            "speed": "R√°pido",
            "quality": "Excelente",
            "context": "131K",
        }
    },
    "CONFIG_GUIDE": """
    Para alterar as configura√ß√µes globais:
    
    1. **Execute o setup:**
    ```bash
    python setup_env.py
    ```
    
    2. **Ou edite o arquivo `.env` manualmente:**
    ```bash
    GLOBAL_TEMPERATURE=0.7      # Criatividade (0.0-1.0)
    GLOBAL_MAX_TOKENS=1000      # Tamanho m√°ximo das respostas
    API_TIMEOUT=30              # Timeout em segundos
    AUTO_RETRY=true             # Retry autom√°tico
    MAX_RETRIES=3               # N√∫mero de tentativas
    LOG_LEVEL=INFO              # DEBUG, INFO, WARNING, ERROR
    DEBUG_MODE=false            # Modo debug
    ```
    
    3. **Execute localmente:**
    ```bash
    streamlit run app.py
    ```
    **Ou reinicie a aplica√ß√£o** caso j√° esteja rodando para aplicar as mudan√ßas.
    """,
    "FOOTER": """
    <div style="text-align: center; color: #666; margin-top: 2rem;">
        <p>ü§ñ <strong>Sistema de IA Generativa Multi-Funcional</strong></p>
        <p><em>Tecnologias: Python ‚Ä¢ LangChain ‚Ä¢ Streamlit ‚Ä¢ Groq ‚Ä¢ NLTK</em></p>
        <p style="margin-top: 1rem;">
            <a href="https://github.com/PietroFilippo/ChatBot-Simples" target="_blank" style="color: #667eea; text-decoration: none; font-weight: 500;">
                Reposit√≥rio no GitHub
            </a>
        </p>
    </div>
    """
}

# Textos de exemplo
EXAMPLE_TEXTS = {
    "SENTIMENT": [
        "Estou muito feliz com os resultados do projeto! A equipe trabalhou de forma excepcional e superou todas as expectativas.",
        
        "Infelizmente, o sistema apresentou v√°rios bugs cr√≠ticos que me deixaram muito frustrado e preocupado com os prazos.",
        
        "Estou triste e com raiva ao mesmo tempo. Esperava muito mais dessa apresenta√ß√£o, mas foi uma grande decep√ß√£o.",
        
        "Que surpresa incr√≠vel! N√£o esperava receber essa not√≠cia hoje. Estou cheio de alegria e esperan√ßa para o futuro.",
        
        "Sinto uma mistura de medo e esperan√ßa. O novo projeto √© desafiador, mas tamb√©m pode trazer grandes oportunidades.",
        
        "O comportamento dele me causou nojo e indigna√ß√£o. Como algu√©m pode agir dessa forma? Estou completamente decepcionado.",
        
        "Amo muito essa empresa e tenho carinho por todos os colegas. Trabalhar aqui tem sido uma experi√™ncia maravilhosa.",
        
        "Estou ansioso e preocupado com os resultados, mas tamb√©m mantenho a confian√ßa de que tudo dar√° certo no final."
    ],
    "SUMMARIZER": """A intelig√™ncia artificial (IA) √© uma das tecnologias mais revolucion√°rias do s√©culo XXI, transformando drasticamente a forma como vivemos, trabalhamos e interagimos com o mundo. Desde sistemas de recomenda√ß√£o em plataformas de streaming at√© carros aut√¥nomos, a IA est√° presente em in√∫meras aplica√ß√µes do nosso cotidiano.

Os modelos de linguagem de grande escala, como GPT e BERT, representam um marco significativo no processamento de linguagem natural. Estes modelos s√£o capazes de compreender contexto, gerar texto coerente e realizar tarefas complexas de compreens√£o textual. A arquitetura transformer, introduzida em 2017, revolucionou o campo e se tornou a base para a maioria dos modelos de IA generativa atuais.

No entanto, o desenvolvimento da IA tamb√©m traz desafios importantes. Quest√µes √©ticas, como vi√©s algor√≠tmico, privacidade de dados e o impacto no mercado de trabalho, precisam ser cuidadosamente consideradas. √â essencial desenvolver IA de forma respons√°vel, garantindo que os benef√≠cios sejam amplamente distribu√≠dos e os riscos minimizados.

O futuro da IA promete ainda mais avan√ßos, com pesquisas em andamento sobre IA geral artificial, computa√ß√£o qu√¢ntica aplicada √† IA e sistemas multimodais que podem processar texto, imagem e √°udio simultaneamente. Estas inova√ß√µes t√™m o potencial de resolver problemas complexos em √°reas como medicina, mudan√ßas clim√°ticas e educa√ß√£o."""
}

# Emojis para sentimentos
SENTIMENT_EMOJIS = {
    "positive": "üòä",
    "negative": "üòû",
    "neutral": "üòê",
    "mixed": "üé≠",
    "very_positive": "ü§©",
    "very_negative": "üò¢",
}

# Emojis para complexidade emocional
COMPLEXITY_EMOJIS = {
    "simple": "üîµ",
    "moderate": "üü°",
    "complex": "üî¥",
}

# Cores para diferentes categorias
COLORS = {
    "positive": "#28a745",  # Verde
    "negative": "#dc3545",  # Vermelho
    "neutral": "#6c757d",   # Cinza
    "primary": "#667eea",   # Azul prim√°rio
    "secondary": "#764ba2", # Roxo secund√°rio
}

# Configura√ß√µes de UI
UI_CONFIG = {
    "max_text_display_length": 500,
    "min_text_length": 10,
    "chat_message_height": 200,
    "sidebar_width": 300,
    "default_temperature": 0.7,
    "default_max_tokens": 1000,
}

# URLs importantes
URLS = {
    "groq_console": "https://console.groq.com/",
    "huggingface_tokens": "https://huggingface.co/settings/tokens",
    "github_repo": "https://github.com/PietroFilippo/ChatBot-Simples",
    "documentation": "#",  # Placeholder
}

# Instru√ß√µes de configura√ß√£o
CONFIG_INSTRUCTIONS = {
    "groq": """
    **Para configurar Groq:**
    1. Execute: `python setup_env.py`
    2. Configure sua chave quando solicitado
    3. Obtenha gr√°tis em: [console.groq.com](https://console.groq.com/)
    """,
    "huggingface": """
    **Para configurar Hugging Face:**
    1. Execute: `python setup_env.py`
    2. Configure sua chave quando solicitado
    3. Obtenha gr√°tis em: [huggingface.co/settings/tokens](https://huggingface.co/settings/tokens)
    """,
}

# Status indicators
STATUS_INDICATORS = {
    "available": "‚úÖ",
    "unavailable": "‚öôÔ∏è",
    "error": "‚ùå",
    "loading": "‚è≥",
    "active": "üéØ",
}

# Personalidades do chatbot
CHATBOT_PERSONALITIES = {
    "helpful": {
        "name": "√ötil",
        "emoji": "ü§ù",
        "description": "Assistente prestativo e direto"
    },
    "creative": {
        "name": "Criativo", 
        "emoji": "üé®",
        "description": "Pensador criativo e imaginativo"
    },
    "technical": {
        "name": "T√©cnico",
        "emoji": "üîß",
        "description": "Especialista t√©cnico detalhado"
    },
}

# Tipos de resumo
SUMMARY_TYPES = {
    "informative": {
        "name": "Informativo",
        "emoji": "üìã",
        "description": "Resumo factual e objetivo"
    },
    "executive": {
        "name": "Executivo",
        "emoji": "üíº", 
        "description": "Resumo para tomada de decis√£o"
    },
    "creative": {
        "name": "Criativo",
        "emoji": "üé≠",
        "description": "Resumo com estilo narrativo"
    },
    "technical": {
        "name": "T√©cnico",
        "emoji": "‚öôÔ∏è",
        "description": "Resumo com foco t√©cnico"
    },
}

# Limites e configura√ß√µes
LIMITS = {
    "max_chat_history": 50,
    "max_file_size_mb": 10,
    "max_text_length": 50000,
    "min_summary_length": 50,
    "max_retries": 3,
    "request_timeout": 30,
} 